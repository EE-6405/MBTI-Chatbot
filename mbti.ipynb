{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/mbti-personality-types-500-dataset/MBTI 500.csv')\n",
    "\n",
    "mbti_counts = df['type'].value_counts()\n",
    "# 假设df是从文件中正确加载的DataFrame，并且 'type' 列包含了MBTI类型\n",
    "\n",
    "# 去除NaN值\n",
    "df = df.dropna(subset=['type'])\n",
    "\n",
    "# 计算每个分类的数量\n",
    "categories = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "counts = {category: {'I': 0, 'E': 0, 'N': 0, 'S': 0, 'T': 0, 'F': 0, 'J': 0, 'P': 0} for category in categories}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_type = row['type']\n",
    "    counts['I/E'][mbti_type[0]] += 1\n",
    "    counts['N/S'][mbti_type[1]] += 1\n",
    "    counts['T/F'][mbti_type[2]] += 1\n",
    "    counts['J/P'][mbti_type[3]] += 1\n",
    "\n",
    "# 转换计数到DataFrame准备绘图\n",
    "df_counts = pd.DataFrame(counts)\n",
    "\n",
    "df_origin = df\n",
    "df_origin.rename(columns={'type': 'type_mbti'}, inplace=True)\n",
    "\n",
    "mbti_type = pd.DataFrame\n",
    "mbti_type = df['type_mbti']\n",
    "\n",
    "label_map_all = {\n",
    "    'ISTJ': 1, 'ISFJ': 2, 'INFJ': 3, 'INTJ': 4,\n",
    "    'ISTP': 5, 'ISFP': 6, 'INFP': 7, 'INTP': 8,\n",
    "    'ESTP': 9, 'ESFP': 10, 'ENFP':11, 'ENTP':12,\n",
    "    'ESTJ': 13, 'ESFJ':14, 'ENFJ':15, 'ENTJ':16\n",
    "}\n",
    "\n",
    "label_map_ie = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 1, 'INTP': 1,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 0, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_sn = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 0, 'INTJ': 0,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 2, 'INTP': 0,\n",
    "    'ESTP': 1, 'ESFP': 1, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_tf = {\n",
    "    'ISTJ': 1, 'ISFJ': 0, 'INFJ': 0, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 0, 'INFP': 0, 'INTP': 1,\n",
    "    'ESTP': 1, 'ESFP': 0, 'ENFP': 0, 'ENTP': 1,\n",
    "    'ESTJ': 1, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 1\n",
    "}\n",
    "label_map_jp = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 0, 'ISFP': 0, 'INFP': 0, 'INTP': 0,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 1, 'ENTJ': 1\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 創建新的 DataFrame，複製舊 DataFrame 中的所有列\n",
    "new_df = df.copy()\n",
    "\n",
    "# 使用 map 函數將 MBTI 類型映射為對應的數字或類別，填充到五個新列中\n",
    "new_df['mbti_all'] = df['type_mbti'].map(label_map_all)\n",
    "new_df['mbti_ie'] = df['type_mbti'].map(label_map_ie)\n",
    "new_df['mbti_sn'] = df['type_mbti'].map(label_map_sn)\n",
    "new_df['mbti_tf'] = df['type_mbti'].map(label_map_tf)\n",
    "new_df['mbti_jp'] = df['type_mbti'].map(label_map_jp)\n",
    "\n",
    "# 刪除原來的 'type_mbti' 列\n",
    "new_df.drop(columns=['type_mbti'], inplace=True)\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc585764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # 导入 tqdm 用于进度条\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98579f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = new_df\n",
    "\n",
    "# data = data.iloc[0:10000]\n",
    "data = data.sample(n=10000, replace=False, random_state=42)\n",
    "\n",
    "# 分割数据\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集类\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['posts']\n",
    "        labels = [row[f'mbti_{dim}'] for dim in ['ie', 'sn', 'tf', 'jp']]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# 初始化tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 创建数据加载器\n",
    "max_len = 512\n",
    "train_dataset = MBTIDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = MBTIDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "class MultiTaskBert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert.gradient_checkpointing_enable()  # 启用检查点\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifiers = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(768, 1) for _ in range(4)\n",
    "        ])\n",
    "    \n",
    "    # def forward(self, input_ids, attention_mask):\n",
    "    #     outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    #     pooled_output = outputs[1]\n",
    "    #     pooled_output = self.dropout(pooled_output)\n",
    "    #     logits = torch.cat([classifier(pooled_output).squeeze() for classifier in self.classifiers], dim=-1)\n",
    "    #     return logits\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # [batch_size, 768]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = torch.cat([classifier(pooled_output) for classifier in self.classifiers], dim=-1)  # [batch_size, 4]\n",
    "        return logits\n",
    "\n",
    "model = MultiTaskBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d435ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 确定保存模型的目录\n",
    "model_save_path = './model/models'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f53187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备和模型初始化\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiTaskBert()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"使用 {torch.cuda.device_count()} 块 GPU\")\n",
    "    model = nn.DataParallel(model)  # 启用数据并行\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # 使用 tqdm 包装 data_loader，显示进度条\n",
    "    for batch in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, labels)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    final_outputs = []\n",
    "    final_labels = []\n",
    "    # 使用 tqdm 包装 data_loader，显示进度条\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            final_outputs.append(outputs.cpu().numpy())\n",
    "            final_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    final_outputs = np.concatenate(final_outputs, axis=0)\n",
    "    final_labels = np.concatenate(final_labels, axis=0)\n",
    "    # 转换为二分类预测\n",
    "    preds = (torch.sigmoid(torch.tensor(final_outputs)) > 0.5).numpy()  # [num_samples, 4]\n",
    "    \n",
    "    # 计算每个维度的准确率\n",
    "    accuracies = []\n",
    "    dimension_names = ['E/I', 'N/S', 'T/F', 'J/P']\n",
    "    for dim in range(4):\n",
    "        acc = accuracy_score(final_labels[:, dim], preds[:, dim])\n",
    "        accuracies.append(acc)\n",
    "        print(f\"{dimension_names[dim]} 准确率: {acc:.4f}\")\n",
    "    \n",
    "    return preds, final_labels, accuracies\n",
    "\n",
    "num_epochs = 3\n",
    "best_metric = float('inf')  # 基于训练损失\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    preds, final_labels, accuracies = eval_model(model, test_loader, device)\n",
    "    avg_acc = sum(accuracies) / len(accuracies)\n",
    "    print(f\"第 {epoch + 1} 轮评估完成，平均准确率: {avg_acc:.4f}\")\n",
    "    # print(f\"第 {epoch + 1} 轮评估完成，准确率: {accuracies}\")\n",
    "    # 保存最佳模型（基于训练损失）\n",
    "    if train_loss < best_metric:\n",
    "        best_metric = train_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path, 'best_model.pth'))\n",
    "        print(f\"最佳模型已保存至 {os.path.join(model_save_path, 'best_model.pth')}，训练损失: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc644d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果拼接为 MBTI 类型\n",
    "def predictions_to_mbti(preds):\n",
    "    mbti_types = []\n",
    "    for pred in preds:\n",
    "        ei = 'E' if pred[0] == 1 else 'I'\n",
    "        ns = 'N' if pred[1] == 1 else 'S'\n",
    "        tf = 'T' if pred[2] == 1 else 'F'\n",
    "        jp = 'J' if pred[3] == 1 else 'P'\n",
    "        mbti_types.append(ei + ns + tf + jp)\n",
    "    return mbti_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5768f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_with_probability_scores(model, data_loader, device, original_data=None):\n",
    "#     model.eval()\n",
    "#     final_outputs = []\n",
    "#     final_labels = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(data_loader, desc=\"Predicting\", leave=True):\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch.get('labels')  # Labels may not exist in prediction\n",
    "#             if labels is not None:\n",
    "#                 labels = labels.to(device)\n",
    "#                 final_labels.append(labels.cpu())\n",
    "            \n",
    "#             logits = model(input_ids, attention_mask)\n",
    "#             final_outputs.append(logits.cpu())\n",
    "    \n",
    "#     final_outputs = torch.cat(final_outputs, dim=0)\n",
    "#     probs = torch.sigmoid(final_outputs).numpy()  # Probabilities [num_samples, 4]\n",
    "#     preds = (probs > 0.5).astype(int)  # Binary predictions [num_samples, 4]\n",
    "    \n",
    "#     # Compute scores: probability of the predicted class\n",
    "#     scores = np.zeros_like(probs)\n",
    "#     for i in range(probs.shape[0]):\n",
    "#         for j in range(probs.shape[1]):\n",
    "#             scores[i, j] = probs[i, j] if preds[i, j] == 1 else 1 - probs[i, j]\n",
    "    \n",
    "#     # Create DataFrame for predictions and scores\n",
    "#     pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "#     score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "#     pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "#     score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    \n",
    "#     if original_data is not None:\n",
    "#         results_df = original_data.reset_index(drop=True).copy()\n",
    "#         results_df = pd.concat([results_df, pred_df, score_df], axis=1)\n",
    "#     else:\n",
    "#         results_df = pd.concat([pred_df, score_df], axis=1)\n",
    "    \n",
    "#     # If labels are available, compute accuracies\n",
    "#     accuracies = None\n",
    "#     if final_labels:\n",
    "#         final_labels = torch.cat(final_labels, dim=0).numpy()\n",
    "#         accuracies = []\n",
    "#         dimension_names = ['E/I', 'N/S', 'T/F', 'J/P']\n",
    "#         for dim in range(4):\n",
    "#             acc = accuracy_score(final_labels[:, dim], preds[:, dim])\n",
    "#             accuracies.append(acc)\n",
    "#             print(f\"{dimension_names[dim]} Accuracy: {acc:.4f}\")\n",
    "    \n",
    "#     return results_df, accuracies\n",
    "def predict_text(model, texts, tokenizer, device, max_len=128, batch_size=16, preprocess=True):\n",
    "    \"\"\"\n",
    "    Predict MBTI dimensions for input text(s) with probability scores.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MultiTaskBert model\n",
    "        texts: Single string or list of strings\n",
    "        tokenizer: BERT tokenizer\n",
    "        device: torch.device (cuda or cpu)\n",
    "        max_len: Maximum sequence length\n",
    "        batch_size: Batch size for prediction\n",
    "        preprocess: Whether to apply preprocess_text\n",
    "    \n",
    "    Returns:\n",
    "        results_df: Pandas DataFrame with original text, cleaned text, predictions, and scores\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert single text to list\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    # Preprocess texts if required\n",
    "    cleaned_texts = [preprocess_text(text) if preprocess else text for text in texts]\n",
    "    \n",
    "    # Create DataFrame for input texts\n",
    "    input_df = pd.DataFrame({'original_text': texts, 'cleaned_text': cleaned_texts})\n",
    "    \n",
    "    # Tokenize cleaned texts\n",
    "    encodings = [tokenizer.encode_plus(\n",
    "        cleaned_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ) for cleaned_text in cleaned_texts]\n",
    "    \n",
    "    input_ids = torch.cat([enc['input_ids'] for enc in encodings], dim=0)\n",
    "    attention_mask = torch.cat([enc['attention_mask'] for enc in encodings], dim=0)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(input_ids, attention_mask)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    final_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Predicting\", leave=True):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            final_outputs.append(logits.cpu())\n",
    "    \n",
    "    final_outputs = torch.cat(final_outputs, dim=0)\n",
    "    probs = torch.sigmoid(final_outputs).numpy()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    \n",
    "    # Compute scores: probability of predicted class\n",
    "    scores = np.zeros_like(probs)\n",
    "    for i in range(probs.shape[0]):\n",
    "        for j in range(probs.shape[1]):\n",
    "            scores[i, j] = probs[i, j] if preds[i, j] == 1 else 1 - probs[i, j]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "    score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "    pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "    score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    # 拼接 MBTI 类型\n",
    "    mbti_types = predictions_to_mbti(preds)\n",
    "    # 创建 DataFrame\n",
    "    pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "    score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "    pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "    score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    mbti_df = pd.DataFrame({'mbti_type': mbti_types})\n",
    "    \n",
    "    results_df = pd.concat([input_df, pred_df, score_df, mbti_df], axis=1)\n",
    "    \n",
    "    # results_df = pd.concat([input_df, pred_df, score_df], axis=1)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7156968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# 确保已经下载了nltk中的停止词和词形还原器的数据\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # 移除表情符号和特殊字符\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # 分词\n",
    "    words = text.split()\n",
    "\n",
    "    # 词形还原和去除停止词\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    return ' '.join(cleaned_text)\n",
    "\n",
    "# 示例文本\n",
    "sample_text = (\"2024 starts with a bang 😅. Everyone's year-end summaries are so brilliant, compared to them it feels like I haven't lived at all. By contrast, I feel a year younger 😘.Today in class, I realized I lost my red pen. I remembered that my Python exam teacher borrowed it yesterday and didn't return it 😅.I only realized after the exam that there's a mode on the calculator that can calculate variance with just one click 😅. When I asked my classmate how he knew, he said that calculators are allowed in Shanghai's college entrance exams, and they learned it quite early.During the trial, it was clearly stated that Trump had never been involved with Epstein Island. I'm surprised he didn't fabricate millions of pages of documents to drag Trump down, I'm devastated.Mariah Carey, you really have a discerning eye. At that time, you shot a music video for this song with a low-budget 'nobody cares' special effect, and indeed, this song has remained popular.\")\n",
    "# cleaned_text = preprocess_text(sample_text)\n",
    "# print(\"Cleaned text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e45441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = MultiTaskBert()\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = os.path.join(model_save_path, 'best_model.pth')\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"模型文件 {model_path} 不存在\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# model.eval()\n",
    "print(f\"模型已从 {model_path} 加载\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载分词器和模型\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# # 对文本进行编码\n",
    "# encoded_input = tokenizer.encode_plus(\n",
    "#     cleaned_text,\n",
    "#     add_special_tokens=True,\n",
    "#     max_length=64,\n",
    "#     padding='max_length',\n",
    "#     return_attention_mask=True,\n",
    "#     truncation=True,\n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "# input_ids = encoded_input['input_ids'].to(device)\n",
    "# attention_mask = encoded_input['attention_mask'].to(device)\n",
    "# # 示例：预测新输入文本\n",
    "# input_texts = cleaned_text\n",
    "# 进行预测\n",
    "results_df = predict_text(model, input_texts, tokenizer, device)\n",
    "# results_df.to_csv('prediction_results_with_prob_scores.csv', index=False)\n",
    "# print(\"Prediction results saved to 'prediction_results_with_prob_scores.csv'\")\n",
    "# if accuracies:\n",
    "#     print(f\"Dimension accuracies: {dict(zip(['E/I', 'N/S', 'T/F', 'J/P'], accuracies))}\")\n",
    "\n",
    "print(\"Prediction results saved to 'text_prediction_results.csv'\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
