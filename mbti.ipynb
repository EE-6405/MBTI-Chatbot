{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/mbti-personality-types-500-dataset/MBTI 500.csv')\n",
    "\n",
    "mbti_counts = df['type'].value_counts()\n",
    "# å‡è®¾dfæ˜¯ä»æ–‡ä»¶ä¸­æ­£ç¡®åŠ è½½çš„DataFrameï¼Œå¹¶ä¸” 'type' åˆ—åŒ…å«äº†MBTIç±»å‹\n",
    "\n",
    "# å»é™¤NaNå€¼\n",
    "df = df.dropna(subset=['type'])\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„æ•°é‡\n",
    "categories = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "counts = {category: {'I': 0, 'E': 0, 'N': 0, 'S': 0, 'T': 0, 'F': 0, 'J': 0, 'P': 0} for category in categories}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_type = row['type']\n",
    "    counts['I/E'][mbti_type[0]] += 1\n",
    "    counts['N/S'][mbti_type[1]] += 1\n",
    "    counts['T/F'][mbti_type[2]] += 1\n",
    "    counts['J/P'][mbti_type[3]] += 1\n",
    "\n",
    "# è½¬æ¢è®¡æ•°åˆ°DataFrameå‡†å¤‡ç»˜å›¾\n",
    "df_counts = pd.DataFrame(counts)\n",
    "\n",
    "df_origin = df\n",
    "df_origin.rename(columns={'type': 'type_mbti'}, inplace=True)\n",
    "\n",
    "mbti_type = pd.DataFrame\n",
    "mbti_type = df['type_mbti']\n",
    "\n",
    "label_map_all = {\n",
    "    'ISTJ': 1, 'ISFJ': 2, 'INFJ': 3, 'INTJ': 4,\n",
    "    'ISTP': 5, 'ISFP': 6, 'INFP': 7, 'INTP': 8,\n",
    "    'ESTP': 9, 'ESFP': 10, 'ENFP':11, 'ENTP':12,\n",
    "    'ESTJ': 13, 'ESFJ':14, 'ENFJ':15, 'ENTJ':16\n",
    "}\n",
    "\n",
    "label_map_ie = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 1, 'INTP': 1,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 0, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_sn = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 0, 'INTJ': 0,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 2, 'INTP': 0,\n",
    "    'ESTP': 1, 'ESFP': 1, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_tf = {\n",
    "    'ISTJ': 1, 'ISFJ': 0, 'INFJ': 0, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 0, 'INFP': 0, 'INTP': 1,\n",
    "    'ESTP': 1, 'ESFP': 0, 'ENFP': 0, 'ENTP': 1,\n",
    "    'ESTJ': 1, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 1\n",
    "}\n",
    "label_map_jp = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 0, 'ISFP': 0, 'INFP': 0, 'INTP': 0,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 1, 'ENTJ': 1\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# å‰µå»ºæ–°çš„ DataFrameï¼Œè¤‡è£½èˆŠ DataFrame ä¸­çš„æ‰€æœ‰åˆ—\n",
    "new_df = df.copy()\n",
    "\n",
    "# ä½¿ç”¨ map å‡½æ•¸å°‡ MBTI é¡å‹æ˜ å°„ç‚ºå°æ‡‰çš„æ•¸å­—æˆ–é¡åˆ¥ï¼Œå¡«å……åˆ°äº”å€‹æ–°åˆ—ä¸­\n",
    "new_df['mbti_all'] = df['type_mbti'].map(label_map_all)\n",
    "new_df['mbti_ie'] = df['type_mbti'].map(label_map_ie)\n",
    "new_df['mbti_sn'] = df['type_mbti'].map(label_map_sn)\n",
    "new_df['mbti_tf'] = df['type_mbti'].map(label_map_tf)\n",
    "new_df['mbti_jp'] = df['type_mbti'].map(label_map_jp)\n",
    "\n",
    "# åˆªé™¤åŸä¾†çš„ 'type_mbti' åˆ—\n",
    "new_df.drop(columns=['type_mbti'], inplace=True)\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc585764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # å¯¼å…¥ tqdm ç”¨äºè¿›åº¦æ¡\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98579f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "data = new_df\n",
    "\n",
    "# data = data.iloc[0:10000]\n",
    "data = data.sample(n=10000, replace=False, random_state=42)\n",
    "\n",
    "# åˆ†å‰²æ•°æ®\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†ç±»\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['posts']\n",
    "        labels = [row[f'mbti_{dim}'] for dim in ['ie', 'sn', 'tf', 'jp']]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# åˆå§‹åŒ–tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "max_len = 512\n",
    "train_dataset = MBTIDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = MBTIDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ­å»ºæ¨¡å‹\n",
    "class MultiTaskBert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert.gradient_checkpointing_enable()  # å¯ç”¨æ£€æŸ¥ç‚¹\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifiers = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(768, 1) for _ in range(4)\n",
    "        ])\n",
    "    \n",
    "    # def forward(self, input_ids, attention_mask):\n",
    "    #     outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    #     pooled_output = outputs[1]\n",
    "    #     pooled_output = self.dropout(pooled_output)\n",
    "    #     logits = torch.cat([classifier(pooled_output).squeeze() for classifier in self.classifiers], dim=-1)\n",
    "    #     return logits\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # [batch_size, 768]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = torch.cat([classifier(pooled_output) for classifier in self.classifiers], dim=-1)  # [batch_size, 4]\n",
    "        return logits\n",
    "\n",
    "model = MultiTaskBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d435ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ç¡®å®šä¿å­˜æ¨¡å‹çš„ç›®å½•\n",
    "model_save_path = './model/models'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f53187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾å¤‡å’Œæ¨¡å‹åˆå§‹åŒ–\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiTaskBert()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ä½¿ç”¨ {torch.cuda.device_count()} å— GPU\")\n",
    "    model = nn.DataParallel(model)  # å¯ç”¨æ•°æ®å¹¶è¡Œ\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    # ä½¿ç”¨ tqdm åŒ…è£… data_loaderï¼Œæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    for batch in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, labels)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    final_outputs = []\n",
    "    final_labels = []\n",
    "    # ä½¿ç”¨ tqdm åŒ…è£… data_loaderï¼Œæ˜¾ç¤ºè¿›åº¦æ¡\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            final_outputs.append(outputs.cpu().numpy())\n",
    "            final_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    final_outputs = np.concatenate(final_outputs, axis=0)\n",
    "    final_labels = np.concatenate(final_labels, axis=0)\n",
    "    # è½¬æ¢ä¸ºäºŒåˆ†ç±»é¢„æµ‹\n",
    "    preds = (torch.sigmoid(torch.tensor(final_outputs)) > 0.5).numpy()  # [num_samples, 4]\n",
    "    \n",
    "    # è®¡ç®—æ¯ä¸ªç»´åº¦çš„å‡†ç¡®ç‡\n",
    "    accuracies = []\n",
    "    dimension_names = ['E/I', 'N/S', 'T/F', 'J/P']\n",
    "    for dim in range(4):\n",
    "        acc = accuracy_score(final_labels[:, dim], preds[:, dim])\n",
    "        accuracies.append(acc)\n",
    "        print(f\"{dimension_names[dim]} å‡†ç¡®ç‡: {acc:.4f}\")\n",
    "    \n",
    "    return preds, final_labels, accuracies\n",
    "\n",
    "num_epochs = 3\n",
    "best_metric = float('inf')  # åŸºäºè®­ç»ƒæŸå¤±\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    preds, final_labels, accuracies = eval_model(model, test_loader, device)\n",
    "    avg_acc = sum(accuracies) / len(accuracies)\n",
    "    print(f\"ç¬¬ {epoch + 1} è½®è¯„ä¼°å®Œæˆï¼Œå¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f}\")\n",
    "    # print(f\"ç¬¬ {epoch + 1} è½®è¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: {accuracies}\")\n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºè®­ç»ƒæŸå¤±ï¼‰\n",
    "    if train_loss < best_metric:\n",
    "        best_metric = train_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path, 'best_model.pth'))\n",
    "        print(f\"æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ {os.path.join(model_save_path, 'best_model.pth')}ï¼Œè®­ç»ƒæŸå¤±: {best_metric:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc644d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†é¢„æµ‹ç»“æœæ‹¼æ¥ä¸º MBTI ç±»å‹\n",
    "def predictions_to_mbti(preds):\n",
    "    mbti_types = []\n",
    "    for pred in preds:\n",
    "        ei = 'E' if pred[0] == 1 else 'I'\n",
    "        ns = 'N' if pred[1] == 1 else 'S'\n",
    "        tf = 'T' if pred[2] == 1 else 'F'\n",
    "        jp = 'J' if pred[3] == 1 else 'P'\n",
    "        mbti_types.append(ei + ns + tf + jp)\n",
    "    return mbti_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5768f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_with_probability_scores(model, data_loader, device, original_data=None):\n",
    "#     model.eval()\n",
    "#     final_outputs = []\n",
    "#     final_labels = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(data_loader, desc=\"Predicting\", leave=True):\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch.get('labels')  # Labels may not exist in prediction\n",
    "#             if labels is not None:\n",
    "#                 labels = labels.to(device)\n",
    "#                 final_labels.append(labels.cpu())\n",
    "            \n",
    "#             logits = model(input_ids, attention_mask)\n",
    "#             final_outputs.append(logits.cpu())\n",
    "    \n",
    "#     final_outputs = torch.cat(final_outputs, dim=0)\n",
    "#     probs = torch.sigmoid(final_outputs).numpy()  # Probabilities [num_samples, 4]\n",
    "#     preds = (probs > 0.5).astype(int)  # Binary predictions [num_samples, 4]\n",
    "    \n",
    "#     # Compute scores: probability of the predicted class\n",
    "#     scores = np.zeros_like(probs)\n",
    "#     for i in range(probs.shape[0]):\n",
    "#         for j in range(probs.shape[1]):\n",
    "#             scores[i, j] = probs[i, j] if preds[i, j] == 1 else 1 - probs[i, j]\n",
    "    \n",
    "#     # Create DataFrame for predictions and scores\n",
    "#     pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "#     score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "#     pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "#     score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    \n",
    "#     if original_data is not None:\n",
    "#         results_df = original_data.reset_index(drop=True).copy()\n",
    "#         results_df = pd.concat([results_df, pred_df, score_df], axis=1)\n",
    "#     else:\n",
    "#         results_df = pd.concat([pred_df, score_df], axis=1)\n",
    "    \n",
    "#     # If labels are available, compute accuracies\n",
    "#     accuracies = None\n",
    "#     if final_labels:\n",
    "#         final_labels = torch.cat(final_labels, dim=0).numpy()\n",
    "#         accuracies = []\n",
    "#         dimension_names = ['E/I', 'N/S', 'T/F', 'J/P']\n",
    "#         for dim in range(4):\n",
    "#             acc = accuracy_score(final_labels[:, dim], preds[:, dim])\n",
    "#             accuracies.append(acc)\n",
    "#             print(f\"{dimension_names[dim]} Accuracy: {acc:.4f}\")\n",
    "    \n",
    "#     return results_df, accuracies\n",
    "def predict_text(model, texts, tokenizer, device, max_len=128, batch_size=16, preprocess=True):\n",
    "    \"\"\"\n",
    "    Predict MBTI dimensions for input text(s) with probability scores.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MultiTaskBert model\n",
    "        texts: Single string or list of strings\n",
    "        tokenizer: BERT tokenizer\n",
    "        device: torch.device (cuda or cpu)\n",
    "        max_len: Maximum sequence length\n",
    "        batch_size: Batch size for prediction\n",
    "        preprocess: Whether to apply preprocess_text\n",
    "    \n",
    "    Returns:\n",
    "        results_df: Pandas DataFrame with original text, cleaned text, predictions, and scores\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert single text to list\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    # Preprocess texts if required\n",
    "    cleaned_texts = [preprocess_text(text) if preprocess else text for text in texts]\n",
    "    \n",
    "    # Create DataFrame for input texts\n",
    "    input_df = pd.DataFrame({'original_text': texts, 'cleaned_text': cleaned_texts})\n",
    "    \n",
    "    # Tokenize cleaned texts\n",
    "    encodings = [tokenizer.encode_plus(\n",
    "        cleaned_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    ) for cleaned_text in cleaned_texts]\n",
    "    \n",
    "    input_ids = torch.cat([enc['input_ids'] for enc in encodings], dim=0)\n",
    "    attention_mask = torch.cat([enc['attention_mask'] for enc in encodings], dim=0)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataset = torch.utils.data.TensorDataset(input_ids, attention_mask)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    final_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Predicting\", leave=True):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            final_outputs.append(logits.cpu())\n",
    "    \n",
    "    final_outputs = torch.cat(final_outputs, dim=0)\n",
    "    probs = torch.sigmoid(final_outputs).numpy()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    \n",
    "    # Compute scores: probability of predicted class\n",
    "    scores = np.zeros_like(probs)\n",
    "    for i in range(probs.shape[0]):\n",
    "        for j in range(probs.shape[1]):\n",
    "            scores[i, j] = probs[i, j] if preds[i, j] == 1 else 1 - probs[i, j]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "    score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "    pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "    score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    # æ‹¼æ¥ MBTI ç±»å‹\n",
    "    mbti_types = predictions_to_mbti(preds)\n",
    "    # åˆ›å»º DataFrame\n",
    "    pred_columns = ['pred_EI', 'pred_NS', 'pred_TF', 'pred_JP']\n",
    "    score_columns = ['score_EI', 'score_NS', 'score_TF', 'score_JP']\n",
    "    pred_df = pd.DataFrame(preds, columns=pred_columns)\n",
    "    score_df = pd.DataFrame(scores, columns=score_columns)\n",
    "    mbti_df = pd.DataFrame({'mbti_type': mbti_types})\n",
    "    \n",
    "    results_df = pd.concat([input_df, pred_df, score_df, mbti_df], axis=1)\n",
    "    \n",
    "    # results_df = pd.concat([input_df, pred_df, score_df], axis=1)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7156968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# ç¡®ä¿å·²ç»ä¸‹è½½äº†nltkä¸­çš„åœæ­¢è¯å’Œè¯å½¢è¿˜åŸå™¨çš„æ•°æ®\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # ç§»é™¤è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # åˆ†è¯\n",
    "    words = text.split()\n",
    "\n",
    "    # è¯å½¢è¿˜åŸå’Œå»é™¤åœæ­¢è¯\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    return ' '.join(cleaned_text)\n",
    "\n",
    "# ç¤ºä¾‹æ–‡æœ¬\n",
    "sample_text = (\"2024 starts with a bang ğŸ˜…. Everyone's year-end summaries are so brilliant, compared to them it feels like I haven't lived at all. By contrast, I feel a year younger ğŸ˜˜.Today in class, I realized I lost my red pen. I remembered that my Python exam teacher borrowed it yesterday and didn't return it ğŸ˜….I only realized after the exam that there's a mode on the calculator that can calculate variance with just one click ğŸ˜…. When I asked my classmate how he knew, he said that calculators are allowed in Shanghai's college entrance exams, and they learned it quite early.During the trial, it was clearly stated that Trump had never been involved with Epstein Island. I'm surprised he didn't fabricate millions of pages of documents to drag Trump down, I'm devastated.Mariah Carey, you really have a discerning eye. At that time, you shot a music video for this song with a low-budget 'nobody cares' special effect, and indeed, this song has remained popular.\")\n",
    "# cleaned_text = preprocess_text(sample_text)\n",
    "# print(\"Cleaned text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e45441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¨¡å‹\n",
    "model = MultiTaskBert()\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = os.path.join(model_save_path, 'best_model.pth')\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# model.eval()\n",
    "print(f\"æ¨¡å‹å·²ä» {model_path} åŠ è½½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# # å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç \n",
    "# encoded_input = tokenizer.encode_plus(\n",
    "#     cleaned_text,\n",
    "#     add_special_tokens=True,\n",
    "#     max_length=64,\n",
    "#     padding='max_length',\n",
    "#     return_attention_mask=True,\n",
    "#     truncation=True,\n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "# input_ids = encoded_input['input_ids'].to(device)\n",
    "# attention_mask = encoded_input['attention_mask'].to(device)\n",
    "# # ç¤ºä¾‹ï¼šé¢„æµ‹æ–°è¾“å…¥æ–‡æœ¬\n",
    "# input_texts = cleaned_text\n",
    "# è¿›è¡Œé¢„æµ‹\n",
    "results_df = predict_text(model, input_texts, tokenizer, device)\n",
    "# results_df.to_csv('prediction_results_with_prob_scores.csv', index=False)\n",
    "# print(\"Prediction results saved to 'prediction_results_with_prob_scores.csv'\")\n",
    "# if accuracies:\n",
    "#     print(f\"Dimension accuracies: {dict(zip(['E/I', 'N/S', 'T/F', 'J/P'], accuracies))}\")\n",
    "\n",
    "print(\"Prediction results saved to 'text_prediction_results.csv'\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
