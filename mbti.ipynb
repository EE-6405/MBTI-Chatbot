{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/mbti-personality-types-500-dataset/MBTI 500.csv')\n",
    "\n",
    "mbti_counts = df['type'].value_counts()\n",
    "# 假设df是从文件中正确加载的DataFrame，并且 'type' 列包含了MBTI类型\n",
    "\n",
    "# 去除NaN值\n",
    "df = df.dropna(subset=['type'])\n",
    "\n",
    "# 计算每个分类的数量\n",
    "categories = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "counts = {category: {'I': 0, 'E': 0, 'N': 0, 'S': 0, 'T': 0, 'F': 0, 'J': 0, 'P': 0} for category in categories}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    mbti_type = row['type']\n",
    "    counts['I/E'][mbti_type[0]] += 1\n",
    "    counts['N/S'][mbti_type[1]] += 1\n",
    "    counts['T/F'][mbti_type[2]] += 1\n",
    "    counts['J/P'][mbti_type[3]] += 1\n",
    "\n",
    "# 转换计数到DataFrame准备绘图\n",
    "df_counts = pd.DataFrame(counts)\n",
    "\n",
    "df_origin = df\n",
    "df_origin.rename(columns={'type': 'type_mbti'}, inplace=True)\n",
    "\n",
    "mbti_type = pd.DataFrame\n",
    "mbti_type = df['type_mbti']\n",
    "\n",
    "label_map_all = {\n",
    "    'ISTJ': 1, 'ISFJ': 2, 'INFJ': 3, 'INTJ': 4,\n",
    "    'ISTP': 5, 'ISFP': 6, 'INFP': 7, 'INTP': 8,\n",
    "    'ESTP': 9, 'ESFP': 10, 'ENFP':11, 'ENTP':12,\n",
    "    'ESTJ': 13, 'ESFJ':14, 'ENFJ':15, 'ENTJ':16\n",
    "}\n",
    "\n",
    "label_map_ie = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 1, 'INTP': 1,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 0, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_sn = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 0, 'INTJ': 0,\n",
    "    'ISTP': 1, 'ISFP': 1, 'INFP': 2, 'INTP': 0,\n",
    "    'ESTP': 1, 'ESFP': 1, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 0, 'ENTJ': 0\n",
    "}\n",
    "label_map_tf = {\n",
    "    'ISTJ': 1, 'ISFJ': 0, 'INFJ': 0, 'INTJ': 1,\n",
    "    'ISTP': 1, 'ISFP': 0, 'INFP': 0, 'INTP': 1,\n",
    "    'ESTP': 1, 'ESFP': 0, 'ENFP': 0, 'ENTP': 1,\n",
    "    'ESTJ': 1, 'ESFJ': 0, 'ENFJ': 0, 'ENTJ': 1\n",
    "}\n",
    "label_map_jp = {\n",
    "    'ISTJ': 1, 'ISFJ': 1, 'INFJ': 1, 'INTJ': 1,\n",
    "    'ISTP': 0, 'ISFP': 0, 'INFP': 0, 'INTP': 0,\n",
    "    'ESTP': 0, 'ESFP': 0, 'ENFP': 0, 'ENTP': 0,\n",
    "    'ESTJ': 1, 'ESFJ': 1, 'ENFJ': 1, 'ENTJ': 1\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 創建新的 DataFrame，複製舊 DataFrame 中的所有列\n",
    "new_df = df.copy()\n",
    "\n",
    "# 使用 map 函數將 MBTI 類型映射為對應的數字或類別，填充到五個新列中\n",
    "new_df['mbti_all'] = df['type_mbti'].map(label_map_all)\n",
    "new_df['mbti_ie'] = df['type_mbti'].map(label_map_ie)\n",
    "new_df['mbti_sn'] = df['type_mbti'].map(label_map_sn)\n",
    "new_df['mbti_tf'] = df['type_mbti'].map(label_map_tf)\n",
    "new_df['mbti_jp'] = df['type_mbti'].map(label_map_jp)\n",
    "\n",
    "# 刪除原來的 'type_mbti' 列\n",
    "new_df.drop(columns=['type_mbti'], inplace=True)\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc585764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # 导入 tqdm 用于进度条\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = new_df\n",
    "\n",
    "data = data.iloc[0:10000]#截取数据\n",
    "\n",
    "# 分割数据\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集类\n",
    "class MBTIDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['posts']\n",
    "        labels = [row[f'mbti_{dim}'] for dim in ['ie', 'sn', 'tf', 'jp']]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# 初始化tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 创建数据加载器\n",
    "max_len = 512\n",
    "train_dataset = MBTIDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = MBTIDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建模型\n",
    "class MultiTaskBert(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert.gradient_checkpointing_enable()  # 启用检查点\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifiers = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(768, 1) for _ in range(4)\n",
    "        ])\n",
    "    \n",
    "    # def forward(self, input_ids, attention_mask):\n",
    "    #     outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "    #     pooled_output = outputs[1]\n",
    "    #     pooled_output = self.dropout(pooled_output)\n",
    "    #     logits = torch.cat([classifier(pooled_output).squeeze() for classifier in self.classifiers], dim=-1)\n",
    "    #     return logits\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # [batch_size, 768]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = torch.cat([classifier(pooled_output) for classifier in self.classifiers], dim=-1)  # [batch_size, 4]\n",
    "        return logits\n",
    "\n",
    "model = MultiTaskBert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f53187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备和模型初始化\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiTaskBert()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"使用 {torch.cuda.device_count()} 块 GPU\")\n",
    "    model = nn.DataParallel(model)  # 启用数据并行\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    # 使用 tqdm 包装 data_loader，显示进度条\n",
    "    for batch in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    final_outputs = []\n",
    "    final_labels = []\n",
    "    # 使用 tqdm 包装 data_loader，显示进度条\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            final_outputs.append(outputs.cpu().numpy())\n",
    "            final_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    final_outputs = np.concatenate(final_outputs, axis=0)\n",
    "    final_labels = np.concatenate(final_labels, axis=0)\n",
    "    # # 转换为二分类预测\n",
    "    # preds = (torch.sigmoid(torch.tensor(final_outputs)) > 0.5).numpy()  # [num_samples, 4]\n",
    "    \n",
    "    # 转换为二分类预测\n",
    "    preds = (torch.sigmoid(torch.tensor(final_outputs)) > 0.5).numpy()  # [num_samples, 4]\n",
    "    \n",
    "    # 计算每个维度的准确率\n",
    "    accuracies = []\n",
    "    dimension_names = ['E/I', 'N/S', 'T/F', 'J/P']\n",
    "    for dim in range(4):\n",
    "        acc = accuracy_score(final_labels[:, dim], preds[:, dim])\n",
    "        accuracies.append(acc)\n",
    "        print(f\"{dimension_names[dim]} 准确率: {acc:.4f}\")\n",
    "    \n",
    "    return preds, final_labels, accuracies\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    train_epoch(model, train_loader, optimizer, device)\n",
    "    preds, final_labels, accuracies = eval_model(model, test_loader, device)\n",
    "    print(f\"第 {epoch + 1} 轮评估完成，准确率: {accuracies}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
